#!/usr/bin/env python3
from io import StringIO
from collections import deque, defaultdict
from argparse import ArgumentParser, RawTextHelpFormatter, FileType
from functools import partial

import os
import re
import sys
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# plt.style.use('seaborn-dark-palette')
filename = os.path.basename(sys.argv[0])
doc = f"""example:
  {filename}
  {filename} wpm
  {filename} char word
"""

known_hashes = {
    'da4846a3c2a8469dd77c921ab0b0bcd506b6e9f3':
        '300 most common english words',
    '275eb003c4fba77d7e61893c3d9fa869822e06c8':
        '1000 most common english words (no double letters)'
}


def main(graphs, output, mistyped, char_speeds, word_speeds, help):
    if 'wpm' in graphs:
        plot_wpm(output)
    if 'char' in graphs:
        plot_char_speeds(char_speeds, filter_func=str.islower)
    if 'word' in graphs:
        is_word = partial(re.match, r'^[a-z]+$')
        plot_n_best_word_speeds(word_speeds, 50, filter_func=is_word)


def plot_wpm(output):
    """Reads `output` and plots typing speeds uniformly apart.
    Adds a trendline.
    """
    df = pd.read_csv(output, header=None,
                     names=['timestamp', 'wpm', 'accuracy',
                            'actual_duration', 'duration', 'hash'])

    df.timestamp = pd.to_datetime(df.timestamp)
    # df = df.set_index(df.timestamp)

    gdf = defaultdict(lambda: [[], pd.DataFrame()])
    for index, row in df.iterrows():
        h = row['hash']
        indexes, hdf = gdf[h]
        indexes.append(index)
        hdf = hdf.append(row)
        gdf[h] = indexes, hdf

    grouped = sorted(gdf.items(), key=lambda x: x[1][1]['wpm'].mean(),
                     reverse=True)

    fig, ax = plt.subplots()
    colors = iter(plt.rcParams["axes.prop_cycle"].by_key()["color"])
    for h, (indexes, hdf) in grouped:
        if h in known_hashes:
            h = known_hashes[h]
        x = indexes
        y = hdf.wpm
        color = next(colors)
        ax.plot(x, y, label=h, color=color)
        ax.fill_between(x, y, facecolor=color)
        trendline = np.poly1d(np.polyfit(x, y, 1))(x)
        ax.plot(x, trendline, '-', lw=4, color='white')
        ax.plot(x, trendline, '--', lw=2, color=color, label='trendline')

    ax.plot(df.accuracy, color=next(colors), lw=3, label='accuracy [%]')
    ticks = plt.yticks()[0]
    plt.yticks(np.arange(max(0, ticks[0]), ticks[-1], 10))
    plt.xticks(df.index, df.timestamp.dt.date, rotation=90)

    # label only every 50th tick
    for i, label in enumerate(ax.xaxis.get_ticklabels()):
        if i % math.ceil(len(df) / 50):
            label.set_visible(False)

    ax.set_title('typing speed per typing test')
    ax.set_xlabel('test number')
    ax.set_ylabel('wpm')
    ax.legend()
    plt.show()


def plot_char_speeds(char_speeds, filter_func=lambda c: True):
    """Reads last 10000 lines of `char_speeds` and groups them by characters.
    Removes lowest and highest 10% and boxplots the data.

    filter_func: function taking a `char` returning `True` if char should be
    plotted, `False` otherwise. By default plots all characters.
    """
    q = deque(char_speeds, maxlen=10000)
    df = pd.read_csv(StringIO(''.join(q)), header=None,
                     names=['char', 'duration', 'wpm', 'timestamp'])

    gdf = filter(lambda t: filter_func(t[1]['char'].iloc[0]),
                 df.groupby(['char']))
    wpms = []
    chars = []
    mean = []
    for char, df in gdf:
        if filter_func(char):
            q1 = df['wpm'].quantile(0.1)  # noqa
            q3 = df['wpm'].quantile(0.9)  # noqa
            wpm = df.query('@q1 <= wpm <= @q3')['wpm']
            chars.append(char)
            wpms.append(wpm)
            mean.append(df['wpm'].mean())

    assert chars, 'Not enough data'
    fig, ax = plt.subplots()

    ax.boxplot(wpms, labels=chars)
    ax.axhline(y=sum(mean)/len(mean), color='r', linestyle='-', label='mean')

    ticks = plt.yticks()[0]
    plt.yticks(np.arange(ticks[0], ticks[-1], 10))

    ax.set_title('typing speed per character of last 10000 characters')
    ax.set_xlabel('characters')
    ax.set_ylabel('wpm')
    ax.legend()
    plt.show()


def plot_n_best_word_speeds(word_speeds, n, filter_func=lambda w: True):
    """Loads all words from `word_speeds` and groups them by word.
    """
    df = pd.read_csv(word_speeds, header=None,
                     names=['word', 'duration', 'wpm', 'timestamp'])

    gdf = filter(lambda t: filter_func(t[0]), df.groupby(['word']))
    gdf = sorted(gdf, key=lambda x: x[1]['wpm'].median())

    first_half = deque(maxlen=n//2)
    second_half = deque(maxlen=n//2)
    for word, df in gdf:
        if len(first_half) < first_half.maxlen:
            first_half.append((word, df['wpm'], df['wpm'].mean()))
        else:
            second_half.append((word, df['wpm'], df['wpm'].mean()))

    words, wpms, means = zip(*list(first_half) + list(second_half))
    mean = sum(means)/len(means)

    assert words, 'Not enough data'

    fig, ax = plt.subplots()

    ax.boxplot(wpms, labels=words)
    ax.axhline(y=mean, color='r', linestyle='-', label='mean wpm of all words')

    ticks = plt.yticks()[0]
    plt.yticks(np.arange(ticks[0], ticks[-1], 10))
    plt.xticks(rotation=90)

    ax.set_title(f'worst and best {n//2} words')
    ax.set_xlabel('words')
    ax.set_yscale('linear')
    ax.set_ylabel('wpm')
    ax.legend()
    plt.show()


def parse_args():
    """Parses `sys.argv` and returns a dictionary suitable for `main`."""
    parser = ArgumentParser(epilog=doc, formatter_class=RawTextHelpFormatter)

    default = '(default: %(default)s)'
    basedir = os.path.dirname(__file__)
    resultsdir = 'results'
    parser.add_argument('graphs', type=str, nargs='*',
                        default=['wpm'],
                        help='graphs to plot: wpm char word\n' + default)
    parser.add_argument('-o', '--output', type=FileType('r'),
                        default=f'{basedir}/{resultsdir}/results.csv',
                        help='file to store results in\n' + default)
    parser.add_argument('-m', '--mistyped', type=FileType('r'),
                        default=f'{basedir}/{resultsdir}/mistyped_words.csv',
                        help='file to store mistyped words in\n' + default)
    parser.add_argument('-c', '--char_speeds', type=FileType('r'),
                        default=f'{basedir}/{resultsdir}/char_speeds.csv',
                        help='file to store character speeds in\n' + default)
    parser.add_argument('-w', '--word_speeds', type=FileType('r'),
                        default=f'{basedir}/{resultsdir}/word_speeds.csv',
                        help='file to store word speeds in\n' + default)

    return dict(parser.parse_args()._get_kwargs(), help=parser.print_help)


if __name__ == '__main__':
    main(**parse_args())
